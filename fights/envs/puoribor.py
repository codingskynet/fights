"""
Puoribor, a variant of the classical `Quoridor <https://en.wikipedia.org/wiki/Quoridor>`_ game.

Coordinates are specified in the form of `(x, y)`, where `(0, 0)` is the bottom left corner.
All coordinates and directions are absolute and does not change between agents.

Directions
    - Top: `+y`
    - Right: `+x`
    - Bottom: `-y`
    - Left: `-x`
"""

from __future__ import annotations

from dataclasses import dataclass

import numpy as np
from numpy.typing import NDArray
from typing_extensions import TypeAlias

Action: TypeAlias = NDArray[np.int_]
"""
Action type. Encoded as a NumPy array of shape ``(4,)``, in the form of [ `agent_id`, `action_type`, `coordinate_x`, `coordinate_y` ]
.

`agent_id`
    - agent id of action (0 or 1)

`action_type`
    - 0 (move piece)
    - 1 (place wall horizontally)
    - 2 (place wall vertically)
    - 3 (rotate section)

`coordinate_x`, `coordinate_y`
    - position to move the piece to
    - top or left position to place the wall
    - top left position of the section to rotate
"""


@dataclass
class PuoriborState:
    """
    PuoriborState class.

    `board`
        - Array of shape ``(C, W, H)``, where C is channel index and W, H is board width, height.
        - C = 0: one-hot encoded position of agent 0. (starts from top)
        - C = 1: one-hot encoded position of agent 1. (starts from bottom)
        - C = 2: one-hot encoded positions of horizontal walls.
        - C = 3: one-hot encoded positions of vertical walls.

    `walls_remaining`
        - Array of shape ``(2,)``, in the form of [ `agent0_remaining_walls`, `agent1_remaining_walls` ]

    `done`
        - Boolean value indicating whether the game is done.
    """

    board: NDArray[np.int_]
    walls_remaining: NDArray[np.int_]
    done: bool = False


class PuoriborEnv:
    board_size: int = 9
    """
    Size (width and height) of the board.
    """

    max_walls: int = 20
    """
    Maximum allowed walls per agent.
    """

    def step(self, state: PuoriborState, action: Action) -> PuoriborState:
        """
        Step through the game, calculating the next state given the current state and action to take.

        Args:
            target: the object of which the state should be restored.
            state: a dictionary generated by `to_state_dict` with the desired new state for `target`.

        Returns:
            A copy of the object with the restored state.
        """

        agent_id, action_type, x, y = action
        if not (0 <= x < self.board_size and 0 <= y < self.board_size):
            raise ValueError(f"out of board: {(x, y)}")
        if not 0 <= agent_id <= 1:
            raise ValueError(f"invalid agent_id: {agent_id}")

        board = np.copy(state.board)
        walls_remaining = np.copy(state.walls_remaining)

        if action_type == 0:
            current_pos = np.argwhere(state.board[agent_id] == 1)[0]
            new_pos = np.array([x, y])
            opponent_pos = np.argwhere(state.board[1 - agent_id] == 1)[0]
            if np.all(new_pos == opponent_pos):
                raise ValueError("cannot move to opponent's position")

            delta = new_pos - current_pos
            taxicab_dist = np.abs(delta).sum()
            if taxicab_dist == 0:
                raise ValueError("cannot move zero blocks")
            elif taxicab_dist > 2:
                raise ValueError("cannot move more than two blocks")
            elif taxicab_dist == 2:
                if np.all(np.abs(delta) == [1, 1]):
                    raise ValueError("cannot move diagonally")
                if not np.all(current_pos + delta // 2 == opponent_pos):
                    raise ValueError("cannot jump over nothing")

            right_check = delta[0] > 0 and np.any(
                state.board[3, current_pos[0] : new_pos[0], current_pos[1]]
            )
            left_check = delta[0] < 0 and np.any(
                state.board[3, new_pos[0] : current_pos[0], current_pos[1]]
            )
            down_check = delta[1] > 0 and np.any(
                state.board[2, current_pos[0], current_pos[1] : new_pos[1]]
            )
            up_check = delta[1] < 0 and np.any(
                state.board[2, current_pos[0], new_pos[1] : current_pos[1]]
            )
            if right_check or left_check or down_check or up_check:
                raise ValueError("cannot jump over walls")

            board[agent_id][tuple(current_pos)] = 0
            board[agent_id][tuple(new_pos)] = 1
        elif action_type == 1:
            if walls_remaining[agent_id] == 0:
                raise ValueError(f"no walls left for agent {agent_id}")
            if y == self.board_size - 1:
                raise ValueError("cannot place wall on the edge")
            elif x == self.board_size - 1:
                raise ValueError("right section out of board")
            elif np.any(board[2, x : x + 2, y]):
                raise ValueError("wall already placed")
            board[2, x, y] = 1
            board[2, x + 1, y] = 1
            walls_remaining[agent_id] -= 1
        elif action_type == 2:
            if walls_remaining[agent_id] == 0:
                raise ValueError(f"no walls left for agent {agent_id}")
            if x == self.board_size - 1:
                raise ValueError("cannot place wall on the edge")
            elif y == self.board_size - 1:
                raise ValueError("right section out of board")
            elif np.any(board[3, x, y : y + 2]):
                raise ValueError("wall already placed")
            board[3, x, y] = 1
            board[3, x, y + 1] = 1
            walls_remaining[agent_id] -= 1
        elif action_type == 3:
            pass
        else:
            raise ValueError(f"invalid action_type: {action_type}")

        return PuoriborState(
            board=board,
            walls_remaining=walls_remaining,
            done=self._check_wins(state),
        )

    def _check_wins(self, state: PuoriborState) -> bool:
        return state.board[0, :, -1].sum() or state.board[1, :, 0].sum()
